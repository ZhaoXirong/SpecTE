{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942f5f67-9abc-4bf3-a7af-1d7a7bb8f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa85109-aef4-49b3-957e-67acd750d079",
   "metadata": {},
   "source": [
    "(注意)：在此之前，需要将前面两部分得到的数据交叉匹配，结果存放在match中，接下来开始这一步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a554776-6937-430d-b7bd-928aa626b005",
   "metadata": {},
   "source": [
    "# 将匹配表按信噪比snrg分为多个文件，并分别下载链接\n",
    "Dividing the APOGEE-LAMOST cross-match table into intervals according to the signal-to-noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4597305-7f59-4b0b-a4e1-0c71894aca30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 读文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22afcba9-2fa3-4d57-98e9-309358a408df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match = pd.read_csv(r'G:\\Star\\1_Data_download_and_preprocessing\\raw_data_catalogue_label\\DR11_match_denoise_50-200.csv')\n",
    "match = pd.read_csv(r'G:\\Star\\1_Data_download_and_preprocessing\\raw_data_catalogue_label\\match_denoise_100-200_1arc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed3da20-82bc-4087-8b8c-c65b3765d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['obsid_1', 'uid_1', 'snrg_1', 'class_1', 'z_1', 'ra_1', 'dec_1',\n",
       "       'obsid_2', 'uid_2', 'snrg_2', 'class_2', 'z_2', 'ra_2', 'dec_2',\n",
       "       'GroupID', 'GroupSize', 'Separation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b907ebb-abf3-4214-a0af-106adedcd1ec",
   "metadata": {},
   "source": [
    "## 定义拆分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d79d89a3-b144-4e88-bcdf-420d50006811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# folder_path = r'E:\\my_star\\download\\snrg_split'  # 定义保存CSV文件的文件夹路径\n",
    "folder_path = r'./download/snrg_split_match_catalog'  # 定义保存CSV文件的文件夹路径\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    \n",
    "\n",
    "def depart_low(i,j):\n",
    "\n",
    "    snrg=match.iloc[np.where((match[\"snrg_1\"]>=i)&(match[\"snrg_1\"]<j))]\n",
    "\n",
    "    print(\"snrg_{}_{}\".format(i,j),\" len:\",len(snrg))\n",
    "\n",
    "    snrg.to_csv(os.path.join(folder_path, \"match_low_{}_{}.csv\".format(i,j))) \n",
    "\n",
    "    return snrg\n",
    "\n",
    "def depart_high(i,j):\n",
    "\n",
    "    snrg=match.iloc[np.where((match[\"snrg_2\"]>=i)&(match[\"snrg_2\"]<j))]\n",
    "\n",
    "    print(\"snrg_{}_{}\".format(i,j),\" len:\",len(snrg))\n",
    "\n",
    "    snrg.to_csv(os.path.join(folder_path, \"match_high_{}_{}.csv\".format(i,j))) \n",
    "\n",
    "    return snrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32ccd005-e404-4640-919d-6601642a626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depart2_high(i):\n",
    "    snrg=match.iloc[np.where(match[\"snrg_2\"]>=i)]\n",
    "    print(\"snrg_{}\".format(i),\" len:\",len(snrg))\n",
    "    snrg.to_csv(os.path.join(folder_path, \"match_high_{}.csv\".format(i))) \n",
    "    return snrg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eff1dd-658c-45e8-900f-ca02460d8115",
   "metadata": {},
   "source": [
    "## 进行拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91171b01-794f-47e8-b635-31e1cd84df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snrg_0_10  len: 29899\n",
      "snrg_10_20  len: 48786\n",
      "snrg_20_30  len: 47143\n",
      "snrg_30_40  len: 49269\n",
      "snrg_40_50  len: 51967\n"
     ]
    }
   ],
   "source": [
    "# 将低信噪比数据分为5组\n",
    "for i in range(5):\n",
    "    depart_low(10*i,10*(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f6cef3-7b08-439a-a756-ef91813b0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snrg_100_120  len: 111476\n",
      "snrg_120_200  len: 115588\n",
      "snrg_200  len: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obsid_1</th>\n",
       "      <th>uid_1</th>\n",
       "      <th>snrg_1</th>\n",
       "      <th>class_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>ra_1</th>\n",
       "      <th>dec_1</th>\n",
       "      <th>obsid_2</th>\n",
       "      <th>uid_2</th>\n",
       "      <th>snrg_2</th>\n",
       "      <th>class_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>ra_2</th>\n",
       "      <th>dec_2</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>Separation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [obsid_1, uid_1, snrg_1, class_1, z_1, ra_1, dec_1, obsid_2, uid_2, snrg_2, class_2, z_2, ra_2, dec_2, GroupID, GroupSize, Separation]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将高信噪比数据分为3组\n",
    "depart_high(100,120)\n",
    "depart_high(120,200)\n",
    "# depart2_high(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e556b78-d028-4260-b14b-3358009203a3",
   "metadata": {},
   "source": [
    "# 生成obsid 文件\n",
    "\n",
    "这个文件作为下一步下载的目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a494e6c8-b520-4972-89f9-be3bff15defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path =  \"./download/snrg_split_match_catalog\"\n",
    "save_path =  \"./download/download_obsid\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# directory_path =  r'E:\\my_star\\download\\snrg_split'\n",
    "# save_path =  r'E:\\my_star\\download\\download_obsid'\n",
    "\n",
    "file_list = os.listdir(directory_path)\n",
    "\n",
    "# 遍历文件列表\n",
    "for filename in file_list:\n",
    "    file_path= os.path.join(directory_path, filename)  # 当前文件的path\n",
    "    # 检查是否为文件（而非子目录）\n",
    "    if os.path.isfile(file_path):\n",
    "        save_filename = re.sub(r'\\.csv$', '.txt', filename)\n",
    "        save_file_path = os.path.join(save_path,save_filename)\n",
    "        catalog = pd.read_csv(file_path) \n",
    "        \n",
    "\n",
    "        if 'low' in save_file_path:\n",
    "            \n",
    "            observed_ids = set()        \n",
    "            # 打开文件写入数据\n",
    "            with open(save_file_path, 'w') as file:\n",
    "                # 遍历DataFrame的每行\n",
    "                for obsid in catalog['obsid_1']:\n",
    "                    # 检查obsid是否已经在集合中\n",
    "                    if obsid not in observed_ids:\n",
    "                        # 如果不在集合中，写入文件并添加到集合中\n",
    "                        file.write(f'{obsid}\\n')\n",
    "                        observed_ids.add(obsid)  # 将当前obsid添加到集合中，表示已处理\n",
    "                        \n",
    "        if 'high' in save_file_path:\n",
    "            \n",
    "            observed_ids = set()        \n",
    "            # 打开文件写入数据\n",
    "            with open(save_file_path, 'w') as file:\n",
    "                # 遍历DataFrame的每行\n",
    "                for obsid in catalog['obsid_2']:\n",
    "                    # 检查obsid是否已经在集合中\n",
    "                    if obsid not in observed_ids:\n",
    "                        # 如果不在集合中，写入文件并添加到集合中\n",
    "                        file.write(f'{obsid}\\n')\n",
    "                        observed_ids.add(obsid)  # 将当前obsid添加到集合中，表示已处理                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
